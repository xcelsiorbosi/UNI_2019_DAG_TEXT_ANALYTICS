{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "report_url = \"http://hansardpublic.parliament.sa.gov.au/Pages/HansardResult.aspx#/docid/HANSARD-10-25756\"\n",
    "report_text = \"When I tried to get a copy of the commissioner's report after being tabled, why was I basically told that there was a very limited— The PRESIDENT: This is a matter of personal explanation in a supplementary. Just please, the Hon. Mr Wortley, ask your supplementary. The Hon. R.P. WORTLEY: Why weren't all members of parliament given a copy of the royal commission's report? The Hon. D.W. Ridgway: But you told us before you never read reports. The Hon. R.I. LUCAS (Treasurer) (15:26): Mr President, I won't go down that particular path, as delicious as that interjection might have been in relation to the Hon. Mr Wortley saying he couldn't trust himself to read his own reports. I don't know why the Hon. Mr Wortley was unable to get a copy of the royal commission report. It was certainly publicly available. If it pleases the member, I will see whether there is not a spare copy somewhere. If we do find a spare copy and give it to him, I will be asking questions afterwards of the honourable member just to make sure he did read it. The Hon. D.W. Ridgway: Do you want it delivered to Scuzzi or something more convenient for you? The PRESIDENT: Are you finished, the Hon. Mr Ridgway? The Hon. R.P. WORTLEY: You just worry about our trade exports, mate, for the state. The PRESIDENT: The Hon. Mr Wortley, I am waiting patiently here to give you the call for your question. Have you finished your private conversation with the Hon. Mr Ridgway? Yes? The Hon. Mr Wortley.\"\n",
    "report_title = \"Murray-Darling Basin Royal Commission\"\n",
    "ai_text = \"In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills. Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning. According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \\\"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. This will require more collaborations and training and working with AI. That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies. The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\\\" The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry. Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public. The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well. This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HansardID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HANSARD-10-26147.xml</td>\n",
       "      <td>Climate Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HANSARD-10-26147.xml</td>\n",
       "      <td>The Hon. M.C. PARNELL (14:55):  I seek leave t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              HansardID                                               Text\n",
       "0  HANSARD-10-26147.xml                                     Climate Change\n",
       "1  HANSARD-10-26147.xml  The Hon. M.C. PARNELL (14:55):  I seek leave t..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data from spreadsheet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_excel (\"..\\\\data\\\\Hansard1102019.xlsx\", sheet_name=\"Text\")\n",
    "df = pd.DataFrame(data, columns= ['HansardID','Text'])\n",
    "df = df.astype({\"HansardID\":'str', \"Text\":'str'}) \n",
    "\n",
    "#df.dtypes \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#hansardFilesInfo = pd.read_excel (\"..\\\\data\\\\HANSARDfullDataset.xlsx\", sheet_name=\"HANSARDFilesInfo\")\n",
    "#hansardFilesInfo = pd.DataFrame(hansardFilesInfo, columns= ['FileName','URL'])\n",
    "#hansardFilesInfo = hansardFilesInfo.astype({\"FileName\":'str', \"URL\":'str'}) \n",
    "#hansardFilesInfo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#header = pd.read_excel (\"..\\\\data\\\\HANSARDfullDataset.xlsx\", sheet_name=\"header\")\n",
    "#header = pd.DataFrame(header)\n",
    "#header.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#bill = pd.read_excel (\"..\\\\data\\\\HANSARDfullDataset.xlsx\", sheet_name=\"bill\")\n",
    "#bill = pd.DataFrame(bill, columns= ['question','bname'])\n",
    "#bill.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HansardID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21289.xml</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21290.xml</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21291.xml</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21292.xml</td>\n",
       "      <td>Public Interest Disclosure Bill. Conference. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21310.xml</td>\n",
       "      <td>Bills. Statutes Amendment (Heavy Vehicles Regi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Text\n",
       "HansardID                                                              \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...\n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...\n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...\n",
       "HANSARD-10-21292.xml  Public Interest Disclosure Bill. Conference. T...\n",
       "HANSARD-10-21310.xml  Bills. Statutes Amendment (Heavy Vehicles Regi..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group text into one document\n",
    "grouped_text = df.groupby('HansardID')['Text'].agg(lambda col: '. '.join(col))\n",
    "grouped_text_df = pd.DataFrame(grouped_text, columns= ['Text'])\n",
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bills. Statutes Amendment (Heavy Vehicles Registration Fees) Bill. Second Reading. Adjourned debate on second reading. (Continued from 1 June 2017.). The Hon. J.M.A. LENSINK (16:35):  I rise to indicate opposition support for this bill, which is part of the harmonisation of national laws which relate to heavy vehicles. In particular, this bill amends the Highways Act and the Motor Vehicles Act so that South Australia can meet its obligations under the Heavy Vehicle National Law (South Australia) Act 2013, which contains the national law as a schedule. This bill provides for the creation of a national heavy vehicle regulator. For the benefit of readers, heavy vehicles are defined as trucks with a gross vehicle mass of 4.5 tonnes or more. The section relating to registration of the national law has not commenced yet, so heavy vehicle registrations remain under state legislation; however, those jurisdictions which are participants, which I understand includes all states and territories except for the Northern Territory and WA, are governed by model law approved by the national Transport and Infrastructure Council, made up of state and territory ministers. Vehicle registration charges are currently calculated on the basis of road user charge and regulatory charge components. Participating jurisdictions have agreed that the revenue which is collected will be transferred to the regulator to undertake its duties. Amendments to the Motor Vehicles Act clarify that deductions from concessional registration charges for people living in remote areas and from primary producers will be taken from the roads component rather than the regulatory component of the fees provided to the regulator's fund. This bill is, in effect, a stopgap to cover arrangements until the other arrangements are completed. I am advised that registration fees will not increase, but a portion will be provided to the NHVR instead of going to the Highways Fund. With those comments, I commend the bill to the house. Debate adjourned on motion of Hon. J.E. Hanson.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_text.iloc[4].replace(\"..\",\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HansardID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21289.xml</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21290.xml</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Text  \\\n",
       "HansardID                                                                 \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...   \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...   \n",
       "\n",
       "                      WordCount  \n",
       "HansardID                        \n",
       "HANSARD-10-21289.xml         16  \n",
       "HANSARD-10-21290.xml         11  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Count number of words in sentence using regex\n",
    "grouped_text_df['WordCount'] = grouped_text_df.apply(lambda x: len(re.findall(r'\\w+', x.Text)), axis=1)\n",
    "grouped_text_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average =  70.2002116730459\n",
      "Median =  46\n",
      "Min =  1\n",
      "Max =  5479\n",
      "Q1 =  6.0\n",
      "Q3 =  110.0\n"
     ]
    }
   ],
   "source": [
    "from statistics import median\n",
    "\n",
    "all_text = df['Text'].agg(lambda col: ''.join(col))\n",
    "all_text = \". \".join(all_text)\n",
    "\n",
    "# Average number of words in a sentence\n",
    "parts = [len(l.split()) for l in re.split(r'[?!.] ', ' '.join(all_text)) if l.strip()]\n",
    "print(\"Average = \", sum(parts)/len(parts))\n",
    "\n",
    "# Median number of words in a sentence\n",
    "print(\"Median = \", median(parts))\n",
    "print(\"Min = \", min(parts))\n",
    "print(\"Max = \", max(parts))\n",
    "print(\"Q1 = \", np.percentile(parts,25))\n",
    "print(\"Q3 = \", np.percentile(parts,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences =  470537\n",
      "Number of sentences with less than 5 words = 83091 : 17.658760097505617\n",
      "Number of sentences with more than 50 words = 224979 : 47.81324316684979\n",
      "Number of sentences with more than 100 words = 132153 : 28.085570316468207\n",
      "Number of sentences with more than 200 words = 30845 : 6.555276205696896\n",
      "Number of sentences with more than 1000 words = 18 : 0.0038254164922205906\n",
      "Remaining sentences [5, 200] = 356601 : 0.7578596369679749\n",
      "Remaining sentences [5, 100] = 255293 : 0.5425566958602618\n",
      "Remaining sentences [5, 50] = 162467 : 0.34527996735644595\n"
     ]
    }
   ],
   "source": [
    "# Number of sentences\n",
    "total_sentences = len(parts)\n",
    "less_than_five = sum(i < 5 for i in parts)\n",
    "greater_than_50 = sum(i > 50 for i in parts)\n",
    "greater_than_100 = sum(i > 100 for i in parts)\n",
    "greater_than_200 = sum(i > 200 for i in parts)\n",
    "greater_than_1000 = sum(i > 1000 for i in parts)\n",
    "\n",
    "print(\"Number of sentences = \", total_sentences)\n",
    "print(\"Number of sentences with less than 5 words =\", less_than_five, \":\", (less_than_five / total_sentences) * 100)\n",
    "print(\"Number of sentences with more than 50 words =\", greater_than_50, \":\", (greater_than_50 / total_sentences) * 100)\n",
    "print(\"Number of sentences with more than 100 words =\", greater_than_100, \":\", (greater_than_100 / total_sentences) * 100)\n",
    "print(\"Number of sentences with more than 200 words =\", greater_than_200, \":\", (greater_than_200 / total_sentences) * 100)\n",
    "print(\"Number of sentences with more than 1000 words =\", greater_than_1000, \":\", (greater_than_1000 / total_sentences) * 100)\n",
    "\n",
    "remaining_sentences = total_sentences - less_than_five - greater_than_200\n",
    "print(\"Remaining sentences [5, 200] =\", remaining_sentences, \":\", remaining_sentences/total_sentences)\n",
    "\n",
    "remaining_sentences = total_sentences - less_than_five - greater_than_100\n",
    "print(\"Remaining sentences [5, 100] =\", remaining_sentences, \":\", remaining_sentences/total_sentences)\n",
    "\n",
    "remaining_sentences = total_sentences - less_than_five - greater_than_50\n",
    "print(\"Remaining sentences [5, 50] =\", remaining_sentences, \":\", remaining_sentences/total_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s = \"1.&#x9;TEST\"\n",
    "s = re.sub(r'[0-9]?.?&#x9;','', s) \n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles and libraries to look into further: \n",
    "* https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "* https://stackabuse.com/text-summarization-with-nltk-in-python/\n",
    "* https://github.com/alanbuxton/PyTeaserPython3\n",
    "* https://github.com/abisee/pointer-generator\n",
    "* https://github.com/DerwenAI/pytextrank\n",
    "* https://github.com/tensorflow/models/tree/master/research/textsum\n",
    "* https://radimrehurek.com/gensim/models/lsimodel.html\n",
    "* https://towardsdatascience.com/text-summarization-in-python-76c0a41f0dc4 (additional links to articles at the end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Base Text Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# The feature base model extracts the features of the sentence, then evaluate its importance\n",
    "# Feature base text summarization by TextTeaser\n",
    "#from pyteaser import SummarizeUrl\n",
    "#url = 'http://www.huffingtonpost.com/2013/11/22/twitter-forward-secrecy_n_4326599.html'\n",
    "#summaries = SummarizeUrl(url)\n",
    "#print summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TextTeasor - automatic summarization algorithm that combines the power of natural language processing and machine learning\n",
    "#from textteaser import TextTeaser\n",
    "#tt = TextTeaser()\n",
    "#tt.summarize(title, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Topic Model summarisation\n",
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "model = LsiModel(common_corpus, id2word=common_dictionary)\n",
    "vectorized_corpus = model[common_corpus]\n",
    "#print(vectorized_corpus)\n",
    "#model.print_topics(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When I tried to get a copy of the commissioner's report after being tabled, why was I basically told that there was a very limited— The PRESIDENT: This is a matter of personal explanation in a...\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smart_truncate(content, length=200, suffix='...'):\n",
    "    if len(content) <= length:\n",
    "        return content\n",
    "    else:\n",
    "        return ' '.join(content[:length+1].split(' ')[0:-1]) + suffix\n",
    "\n",
    "smart_truncate(report_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Truncated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HansardID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21289.xml</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "      <td>16</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21290.xml</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "      <td>11</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21291.xml</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "      <td>18</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21292.xml</td>\n",
       "      <td>Public Interest Disclosure Bill. Conference. T...</td>\n",
       "      <td>69</td>\n",
       "      <td>Public Interest Disclosure Bill. Conference. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21310.xml</td>\n",
       "      <td>Bills. Statutes Amendment (Heavy Vehicles Regi...</td>\n",
       "      <td>327</td>\n",
       "      <td>Bills. Statutes Amendment (Heavy Vehicles Regi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Text  \\\n",
       "HansardID                                                                 \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...   \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...   \n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...   \n",
       "HANSARD-10-21292.xml  Public Interest Disclosure Bill. Conference. T...   \n",
       "HANSARD-10-21310.xml  Bills. Statutes Amendment (Heavy Vehicles Regi...   \n",
       "\n",
       "                      WordCount  \\\n",
       "HansardID                         \n",
       "HANSARD-10-21289.xml         16   \n",
       "HANSARD-10-21290.xml         11   \n",
       "HANSARD-10-21291.xml         18   \n",
       "HANSARD-10-21292.xml         69   \n",
       "HANSARD-10-21310.xml        327   \n",
       "\n",
       "                                                              Truncated  \n",
       "HansardID                                                                \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...  \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...  \n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...  \n",
       "HANSARD-10-21292.xml  Public Interest Disclosure Bill. Conference. T...  \n",
       "HANSARD-10-21310.xml  Bills. Statutes Amendment (Heavy Vehicles Regi...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_text_df['Truncated'] = grouped_text_df.apply(lambda x: smart_truncate(x.Text), axis=1)\n",
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# https://rare-technologies.com/text-summarization-with-gensim/\n",
    "#\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "def get_keywords(text):\n",
    "    keyword_list = keywords(text, split=True, lemmatize=True, deacc=True)\n",
    "    return ', '.join(keyword_list[:10])\n",
    "\n",
    "grouped_text_df['KeyWords'] = grouped_text_df.apply(lambda x: \n",
    "                                                    get_keywords(x.Text), \n",
    "                                                    axis=1)\n",
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "get_keywords(report_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/DerwenAI/pytextrank\n",
    "# https://github.com/DerwenAI/pytextrank/blob/master/example.ipynb\n",
    "# Requires JSON input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "#  TextRank summarization with default parameters\n",
    "grouped_text_df['TextRank'] = grouped_text_df.apply(lambda x: \n",
    "                                                    summarize(x.Text).replace(\"\\n\",\" \").replace(\"..\",\".\"), \n",
    "                                                    axis=1)\n",
    "\n",
    "#  TextRank summarization with no more than 50 words for the summary\n",
    "grouped_text_df['TextRank50'] = grouped_text_df.apply(lambda x: \n",
    "                                                      summarize(x.Text, word_count = 50).replace(\"\\n\",\" \").replace(\"..\",\".\"), \n",
    "                                                      axis=1)\n",
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(summarize(report_text)) #  TextRank summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(summarize(report_text, word_count = 50)) #  TextRank summarization - no more than 50 words for summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(summarize(report_text, ratio = 0.2)) #  TextRank summarization - use no more than 20% of original text for summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "summarize(grouped_text.iloc[4], word_count = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "summarize(grouped_text.iloc[2], word_count = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_text_rank_summary(text):\n",
    "    # Return original text if less than 200 characters long\n",
    "    if len(text) <= 200:\n",
    "        return text\n",
    "    \n",
    "    sentences = []    \n",
    "    text_sentences = re.split(r'[?!.] ', text)\n",
    "    \n",
    "    for sentence in text_sentences:\n",
    "        processed = sentence.replace(\"[^a-zA-Z]\", \" \")\n",
    "        word_count = len(re.findall(r'\\w+', processed)) \n",
    "        if word_count > 1: # Include sentences with more than one word\n",
    "            sentences.append(processed)\n",
    "    \n",
    "    summary = summarize('. '.join(sentences))             \n",
    "    return summary.replace(\"\\n\",\" \").replace(\"..\",\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#  TextRank summarisation with no more than 50 words for the summary\n",
    "grouped_text_df['TextRankProcessed'] = grouped_text_df.apply(lambda x: generate_text_rank_summary(x.Text), axis=1)\n",
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "generate_text_rank_summary(grouped_text.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "generate_text_rank_summary(grouped_text.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "generate_text_rank_summary(report_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\noaka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\noaka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70\n",
    "# Approach uses TextRank algorithm\n",
    "# TextRank does not rely on any previous training data and can work with any arbitrary piece of text. \n",
    "# TextRank is a general purpose graph-based ranking algorithm for NLP\n",
    "\n",
    "# Import all necessary libraries\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer # is based on The Porter Stemming Algorithm\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re \n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Generate clean sentences\n",
    "def create_long_sentences(article, output=True):\n",
    "    sentences = []\n",
    "    \n",
    "    for sentence in article:\n",
    "        sentence = re.sub(r'[0-9]?.?&#x9;','', sentence) # Remove tags\n",
    "        word_count = len(re.findall(r'\\w+', sentence)) \n",
    "        if 4 < word_count <= 100: # Include sentences with 5 to 100 words\n",
    "            sentences.append(sentence.split(\" \"))\n",
    "        if output: \n",
    "            print(sentence, \": words = \", word_count)\n",
    "        \n",
    "    return sentences   \n",
    "\n",
    "\n",
    "# Process word by converting to lowercase, removing punctuation, lemmatising, and stemming. \n",
    "# https://medium.com/@pemagrg/pre-processing-text-in-python-ad13ea544dae\n",
    "def process_word(word):\n",
    "    \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    snowball_stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    word = word.lower() # convert to lowercase\n",
    "    word = word.translate(str.maketrans('', '', string.punctuation)) # remove punctuation \n",
    "    word = wordnet_lemmatizer.lemmatize(word) # lemmatise words\n",
    "    word = snowball_stemmer.stem(word) # stemming\n",
    "    \n",
    "    return word\n",
    "\n",
    "\n",
    "# Process sentence by converting to lowercase, removing punctuation, lemmatising, stemming and removing stopwords. \n",
    "# Sentence must be a list of words that make up the sentence\n",
    "# https://medium.com/@pemagrg/pre-processing-text-in-python-ad13ea544dae\n",
    "def process_sentence(sentence):\n",
    "    \n",
    "    # Process words in sentence\n",
    "    processed_sentence = [process_word(word) for word in sentence]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    processed_sentence = [word for word in processed_sentence if word not in stop_words]\n",
    "    \n",
    "    return processed_sentence\n",
    "\n",
    "\n",
    "# Similarity matrix\n",
    "def sentence_similarity(sent1, sent2):\n",
    "        \n",
    "    all_words = list(set(sent1 + sent2)) \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    \n",
    "    # Vectors must be non-zero to calculate cosine similarity\n",
    "    if np.count_nonzero(vector1) == 0 or np.count_nonzero(vector2) == 0:\n",
    "        return 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "\n",
    "def build_similarity_matrix(sentences):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    \n",
    "    processed_sentences = [process_sentence(sentence) for sentence in sentences]\n",
    "     \n",
    "    for idx1 in range(len(processed_sentences)):\n",
    "        for idx2 in range(len(processed_sentences)):\n",
    "            if idx1 == idx2: # ignore if both are same sentences\n",
    "                continue \n",
    "            sentences_similarity = sentence_similarity(processed_sentences[idx1], processed_sentences[idx2])\n",
    "            similarity_matrix[idx1][idx2] = sentences_similarity\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "# Generate Summary Method\n",
    "def generate_summary_from_file(file_path, top_n=5, output=True):\n",
    "    # Read text and split it into sentences\n",
    "    file = open(file_path, \"r\")\n",
    "    file_data = file.readlines()\n",
    "    sentences = re.split(r'[?!.] ', file_data[0])\n",
    "    \n",
    "    long_sentences = create_long_sentences(sentences, output)\n",
    "    return generate_summary(long_sentences, top_n, output)\n",
    "\n",
    "\n",
    "def generate_summary_from_text(text, top_n=5, output=True):    \n",
    "    \n",
    "    if len(text) <= 200:\n",
    "        # If text is short, return the original text rather than a summary\n",
    "        return text\n",
    "    else:  \n",
    "        # Read text and split it into sentences\n",
    "        sentences = re.split(r'[?!.] ', text)\n",
    "        long_sentences = create_long_sentences(sentences, output)\n",
    "        return generate_summary(long_sentences, top_n, output)  \n",
    "    \n",
    "\n",
    "def generate_summary(sentences, top_n=5, output=True):\n",
    "    summarize_text = []\n",
    "    \n",
    "    # Generate Similarly Matrix across sentences\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences)\n",
    "\n",
    "    # Rank sentences in similarity matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    try: \n",
    "        # https://stackoverflow.com/questions/13040548/networkx-differences-between-pagerank-pagerank-numpy-and-pagerank-scipy\n",
    "        #scores = nx.pagerank(sentence_similarity_graph) # The eigenvector calculation is done by the power iteration method and has no guarantee of convergence\n",
    "        scores = nx.pagerank_numpy(sentence_similarity_graph) # The eigenvector calculation uses NumPy’s interface to the LAPACK eigenvalue solvers. This will be the fastest and most accurate for small graphs.\n",
    "        #scores = nx.pagerank_scipy(sentence_similarity_graph) # SciPy sparse-matrix implementation of the power-method\n",
    "    except nx.NetworkXError:\n",
    "        print (\"NetworkXError\")\n",
    "        return \"\"\n",
    "    except nx.PowerIterationFailedConvergence:\n",
    "        print (\"PowerIterationFailedConvergence\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Sort the rank and pick top sentences\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "    if output:\n",
    "        print(\"Indexes of top ranked_sentence order are \", ranked_sentences)    \n",
    "\n",
    "    if len(ranked_sentences) < top_n:\n",
    "        top_n = len(ranked_sentences)\n",
    "        \n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentences[i][1]))\n",
    "\n",
    "    # Output the summary text        \n",
    "    return '. '.join(summarize_text).replace(\"..\",\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compani', 'provid', 'ai', 'develop', 'tool', 'azur', 'ai', 'servic', 'microsoft', 'cognit', 'servic', 'bot', 'servic', 'azur', 'machin', 'learningaccord', 'manish', 'prakash', 'countri', 'general', 'managerp', 'health', 'educ', 'microsoft', 'india', 'said', 'ai', 'defin', 'technolog', 'time', 'transform', 'life', 'industri', 'job', 'tomorrow', 'requir', 'differ', 'skillset']\n"
     ]
    }
   ],
   "source": [
    "sentence = ['The', 'company', 'will', 'provide', 'AI', 'development', 'tools', 'and', 'Azure', 'AI', 'services', 'such', 'as', 'Microsoft', 'Cognitive', 'Services,', 'Bot', 'Services', 'and', 'Azure', 'Machine', 'Learning.According', 'to', 'Manish', 'Prakash,', 'Country', 'General', 'Manager-PS,', 'Health', 'and', 'Education,', 'Microsoft', 'India,', 'said,', '\"With', 'AI', 'being', 'the', 'defining', 'technology', 'of', 'our', 'time,', 'it', 'is', 'transforming', 'lives', 'and', 'industry', 'and', 'the', 'jobs', 'of', 'tomorrow', 'will', 'require', 'a', 'different', 'skillset']\n",
    "processed_sentence = process_sentence(sentence)\n",
    "print(processed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. This program also included developer-focused AI school that provided a bunch of assets to help build AI skills. The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\" The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's begin\n",
    "generate_summary_from_text(ai_text, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This bill provides for the creation of a national heavy vehicle regulator. Statutes Amendment (Heavy Vehicles Registration Fees) Bill. In particular, this bill amends the Highways Act and the Motor Vehicles Act so that South Australia can meet its obligations under the Heavy Vehicle National Law (South Australia) Act 2013, which contains the national law as a schedule'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary_from_text(grouped_text.iloc[4], 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Statutes Amendment (Possession of Firearms and Prohibited Weapons) Bill. Assent. His Excellency the Governor assented to the bill.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary_from_text(grouped_text.iloc[2], 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr Wortley was unable to get a copy of the royal commission report. WORTLEY: Why weren't all members of parliament given a copy of the royal commission's report. Mr Wortley saying he couldn't trust himself to read his own reports\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary_from_text(report_text, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time = 5644.5772132873535\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all text in data frame and add summary\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "grouped_text_df['TextRankCustom'] = grouped_text_df.apply(lambda x: generate_summary_from_text(x.Text, 3, False), axis=1)\n",
    "\n",
    "t1 = time.time()\n",
    "total_time = t1-t0\n",
    "print(\"Time =\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Truncated</th>\n",
       "      <th>TextRankCustom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HansardID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21289.xml</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "      <td>16</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "      <td>Bills. Children and Young People (Safety) Bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21290.xml</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "      <td>11</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "      <td>Sentencing Bill. Assent. His Excellency the Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21291.xml</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "      <td>18</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "      <td>Statutes Amendment (Possession of Firearms and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21292.xml</td>\n",
       "      <td>Public Interest Disclosure Bill. Conference. T...</td>\n",
       "      <td>69</td>\n",
       "      <td>Public Interest Disclosure Bill. Conference. T...</td>\n",
       "      <td>That the sitting of the council be not suspend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HANSARD-10-21310.xml</td>\n",
       "      <td>Bills. Statutes Amendment (Heavy Vehicles Regi...</td>\n",
       "      <td>327</td>\n",
       "      <td>Bills. Statutes Amendment (Heavy Vehicles Regi...</td>\n",
       "      <td>This bill provides for the creation of a natio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Text  \\\n",
       "HansardID                                                                 \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...   \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...   \n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...   \n",
       "HANSARD-10-21292.xml  Public Interest Disclosure Bill. Conference. T...   \n",
       "HANSARD-10-21310.xml  Bills. Statutes Amendment (Heavy Vehicles Regi...   \n",
       "\n",
       "                      WordCount  \\\n",
       "HansardID                         \n",
       "HANSARD-10-21289.xml         16   \n",
       "HANSARD-10-21290.xml         11   \n",
       "HANSARD-10-21291.xml         18   \n",
       "HANSARD-10-21292.xml         69   \n",
       "HANSARD-10-21310.xml        327   \n",
       "\n",
       "                                                              Truncated  \\\n",
       "HansardID                                                                 \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...   \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...   \n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...   \n",
       "HANSARD-10-21292.xml  Public Interest Disclosure Bill. Conference. T...   \n",
       "HANSARD-10-21310.xml  Bills. Statutes Amendment (Heavy Vehicles Regi...   \n",
       "\n",
       "                                                         TextRankCustom  \n",
       "HansardID                                                                \n",
       "HANSARD-10-21289.xml  Bills. Children and Young People (Safety) Bill...  \n",
       "HANSARD-10-21290.xml  Sentencing Bill. Assent. His Excellency the Go...  \n",
       "HANSARD-10-21291.xml  Statutes Amendment (Possession of Firearms and...  \n",
       "HANSARD-10-21292.xml  That the sitting of the council be not suspend...  \n",
       "HANSARD-10-21310.xml  This bill provides for the creation of a natio...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_text_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel Output of Document Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "grouped_text_df.to_excel('.\\\\DocumentSummary.xlsx', sheet_name='TextRank', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
